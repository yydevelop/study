{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5_ML-Flow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python388jvsc74a57bd0716fbbd92a13ad18c91e0530cf34e461b7b6b5d8d0684ef77aa6c15e96b2fbea",
      "display_name": "Python 3.8.8 64-bit"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsfqfIV8--z8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# データの用意\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "df = sns.load_dataset(\"iris\")  # Irisのデータを取得\n",
        "df.iloc[0, 1] = np.NaN  # わざと欠損値を作る\n",
        "\n",
        "# データの表示\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal_length  sepal_width  petal_length  petal_width species\n",
              "0           5.1          NaN           1.4          0.2  setosa\n",
              "1           4.9          3.0           1.4          0.2  setosa\n",
              "2           4.7          3.2           1.3          0.2  setosa\n",
              "3           4.6          3.1           1.5          0.2  setosa\n",
              "4           5.0          3.6           1.4          0.2  setosa"
            ],
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sepal_length</th>\n      <th>sepal_width</th>\n      <th>petal_length</th>\n      <th>petal_width</th>\n      <th>species</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5.1</td>\n      <td>NaN</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.9</td>\n      <td>3.0</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.7</td>\n      <td>3.2</td>\n      <td>1.3</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.6</td>\n      <td>3.1</td>\n      <td>1.5</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5.0</td>\n      <td>3.6</td>\n      <td>1.4</td>\n      <td>0.2</td>\n      <td>setosa</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzoDOedmNxma",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pandas-profilingのパッケージをインストール\n",
        "!pip install pandas-profiling\n",
        "\n",
        "# データのprofileを作成\n",
        "import pandas_profiling as pdp\n",
        "from IPython.display import HTML\n",
        "\n",
        "profile = pdp.ProfileReport(df)\n",
        "profile.to_file(outputfile=\"profile.html\")\n",
        "HTML(filename='profile.html')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pandas-profiling\n",
            "  Using cached pandas_profiling-3.0.0-py2.py3-none-any.whl (248 kB)\n",
            "Requirement already satisfied: PyYAML>=5.0.0 in c:\\python388\\lib\\site-packages (from pandas-profiling) (5.4.1)\n",
            "Requirement already satisfied: pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3 in c:\\python388\\lib\\site-packages (from pandas-profiling) (1.2.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in c:\\python388\\lib\\site-packages (from pandas-profiling) (1.6.2)\n",
            "Requirement already satisfied: matplotlib>=3.2.0 in c:\\python388\\lib\\site-packages (from pandas-profiling) (3.4.1)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Using cached htmlmin-0.1.12-py3-none-any.whl\n",
            "Requirement already satisfied: joblib in c:\\python388\\lib\\site-packages (from pandas-profiling) (1.0.1)\n",
            "Collecting visions[type_image_path]==0.7.1\n",
            "  Using cached visions-0.7.1-py3-none-any.whl (102 kB)\n",
            "Collecting pydantic>=1.8.1\n",
            "  Using cached pydantic-1.8.2-cp38-cp38-win_amd64.whl (2.0 MB)\n",
            "Collecting missingno>=0.4.2\n",
            "  Using cached missingno-0.4.2-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in c:\\python388\\lib\\site-packages (from pandas-profiling) (4.60.0)\n",
            "Requirement already satisfied: seaborn>=0.10.1 in c:\\python388\\lib\\site-packages (from pandas-profiling) (0.11.1)\n",
            "Collecting tangled-up-in-unicode==0.1.0\n",
            "  Using cached tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
            "Collecting requests>=2.24.0\n",
            "  Using cached requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "Requirement already satisfied: numpy>=1.16.0 in c:\\python388\\lib\\site-packages (from pandas-profiling) (1.20.2)\n",
            "Collecting phik>=0.11.1\n",
            "  Using cached phik-0.11.2-py3-none-any.whl\n",
            "Requirement already satisfied: jinja2>=2.11.1 in c:\\python388\\lib\\site-packages (from pandas-profiling) (2.11.3)\n",
            "Collecting networkx>=2.4\n",
            "  Using cached networkx-2.5.1-py3-none-any.whl (1.6 MB)\n",
            "Collecting multimethod==1.4\n",
            "  Using cached multimethod-1.4-py2.py3-none-any.whl (7.3 kB)\n",
            "Collecting bottleneck\n",
            "  Using cached Bottleneck-1.3.2.tar.gz (88 kB)\n",
            "  Installing build dependencies: started\n",
            "  Installing build dependencies: finished with status 'done'\n",
            "  Getting requirements to build wheel: started\n",
            "  Getting requirements to build wheel: finished with status 'done'\n",
            "    Preparing wheel metadata: started\n",
            "    Preparing wheel metadata: finished with status 'done'\n",
            "Requirement already satisfied: attrs>=19.3.0 in c:\\python388\\lib\\site-packages (from visions[type_image_path]==0.7.1->pandas-profiling) (20.3.0)\n",
            "Requirement already satisfied: Pillow in c:\\python388\\lib\\site-packages (from visions[type_image_path]==0.7.1->pandas-profiling) (8.2.0)\n",
            "Collecting imagehash\n",
            "  Using cached ImageHash-4.2.0-py2.py3-none-any.whl (295 kB)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in c:\\python388\\lib\\site-packages (from jinja2>=2.11.1->pandas-profiling) (1.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\python388\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (2.8.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python388\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python388\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\python388\\lib\\site-packages (from matplotlib>=3.2.0->pandas-profiling) (0.10.0)\n",
            "Requirement already satisfied: six in c:\\python388\\lib\\site-packages (from cycler>=0.10->matplotlib>=3.2.0->pandas-profiling) (1.15.0)\n",
            "Collecting decorator<5,>=4.3\n",
            "  Using cached decorator-4.4.2-py2.py3-none-any.whl (9.2 kB)\n",
            "Requirement already satisfied: pytz>=2017.3 in c:\\python388\\lib\\site-packages (from pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3->pandas-profiling) (2021.1)\n",
            "Collecting typing-extensions>=3.7.4.3\n",
            "  Using cached typing_extensions-3.10.0.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\python388\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in c:\\python388\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\python388\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\python388\\lib\\site-packages (from requests>=2.24.0->pandas-profiling) (2020.12.5)\n",
            "Collecting PyWavelets\n",
            "  Using cached PyWavelets-1.1.1-cp38-cp38-win_amd64.whl (4.3 MB)\n",
            "Building wheels for collected packages: bottleneck\n",
            "  Building wheel for bottleneck (PEP 517): started\n",
            "  Building wheel for bottleneck (PEP 517): finished with status 'error'\n",
            "Failed to build bottleneck\n",
            "WARNING: Value for scheme.headers does not match. Please report this to <https://github.com/pypa/pip/issues/9617>\n",
            "distutils: c:\\python388\\Include\\UNKNOWN\n",
            "sysconfig: c:\\python388\\Include\n",
            "WARNING: Additional context:\n",
            "user = False\n",
            "home = None\n",
            "root = None\n",
            "prefix = None\n",
            "  ERROR: Command errored out with exit status 1:\n",
            "   command: 'c:\\python388\\python.exe' 'c:\\python388\\lib\\site-packages\\pip\\_vendor\\pep517\\in_process\\_in_process.py' build_wheel 'C:\\Users\\cheap\\AppData\\Local\\Temp\\tmp4msf2cbz'\n",
            "       cwd: C:\\Users\\cheap\\AppData\\Local\\Temp\\pip-install-wfvbq2a7\\bottleneck_61d51084d0024ee8a52c7d129e9df91a\n",
            "  Complete output (51 lines):\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build\\lib.win-amd64-3.8\n",
            "  creating build\\lib.win-amd64-3.8\\bottleneck\n",
            "  copying bottleneck\\_pytesttester.py -> build\\lib.win-amd64-3.8\\bottleneck\n",
            "  copying bottleneck\\_version.py -> build\\lib.win-amd64-3.8\\bottleneck\n",
            "  copying bottleneck\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\n",
            "  creating build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
            "  copying bottleneck\\benchmark\\autotimeit.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
            "  copying bottleneck\\benchmark\\bench.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
            "  copying bottleneck\\benchmark\\bench_detailed.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
            "  copying bottleneck\\benchmark\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\benchmark\n",
            "  creating build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
            "  copying bottleneck\\slow\\move.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
            "  copying bottleneck\\slow\\nonreduce.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
            "  copying bottleneck\\slow\\nonreduce_axis.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
            "  copying bottleneck\\slow\\reduce.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
            "  copying bottleneck\\slow\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\slow\n",
            "  creating build\\lib.win-amd64-3.8\\bottleneck\\src\n",
            "  copying bottleneck\\src\\bn_config.py -> build\\lib.win-amd64-3.8\\bottleneck\\src\n",
            "  copying bottleneck\\src\\bn_template.py -> build\\lib.win-amd64-3.8\\bottleneck\\src\n",
            "  copying bottleneck\\src\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\src\n",
            "  creating build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\input_modification_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\list_input_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\memory_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\move_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\nonreduce_axis_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\nonreduce_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\reduce_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\scalar_input_test.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\util.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  copying bottleneck\\tests\\__init__.py -> build\\lib.win-amd64-3.8\\bottleneck\\tests\n",
            "  UPDATING build\\lib.win-amd64-3.8\\bottleneck/_version.py\n",
            "  set build\\lib.win-amd64-3.8\\bottleneck/_version.py to '1.3.2'\n",
            "  running build_ext\n",
            "  running config\n",
            "  compiling '_configtest.c':\n",
            "  \n",
            "  \n",
            "  \n",
            "  int __attribute__((optimize(\"O3\"))) have_attribute_optimize_opt_3(void*);\n",
            "  \n",
            "  int main(void)\n",
            "  {\n",
            "      return 0;\n",
            "  }\n",
            "  \n",
            "  error: Microsoft Visual C++ 14.0 or greater is required. Get it with \"Microsoft C++ Build Tools\": https://visualstudio.microsoft.com/visual-cpp-build-tools/\n",
            "  ----------------------------------------\n",
            "  ERROR: Failed building wheel for bottleneck\n",
            "ERROR: Could not build wheels for bottleneck which use PEP 517 and cannot be installed directly\n",
            "WARNING: You are using pip version 21.1; however, version 21.1.1 is available.\n",
            "You should consider upgrading via the 'c:\\python388\\python.exe -m pip install --upgrade pip' command.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas_profiling'",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-2-865871b1420e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# データのprofileを作成\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpdp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mHTML\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAxq41_gc6ys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ノートブック上にグラフを描画するように設定\n",
        "%matplotlib inline\n",
        "\n",
        "# リスト5.2で欠損値にした箇所に対する計算エラーの警告を出力させないように設定\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "sns.boxplot(x='species', y='sepal_width', hue='species', data=df)\n",
        "sns.pairplot(df, hue='species')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw1Mb-Y0dihO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold\n",
        "\n",
        "# 将来的にデフォルト値が変更される警告が出力されないように設定\n",
        "import warnings\n",
        "warnings.simplefilter('ignore')\n",
        "\n",
        "# 1. 前処理------\n",
        "df = df.dropna()  # 欠損値のあるレコードを削除\n",
        "del df['petal_width']  # データチェックの結果からpetal_lengthと相関が強いpetal_widthは削除\n",
        "\n",
        "# カテゴリーデータであるspecies（種類）を数値データに変換\n",
        "df['species'] = df['species'].map(\n",
        "    {'setosa': 0, 'versicolor': 1, 'virginica': 2})\n",
        "\n",
        "# Numpyの変数を用意\n",
        "y = np.array(df['species'])\n",
        "X = np.array(df.iloc[:, 0:3])  # 0, 1, 2行目の3つを取得\n",
        "\n",
        "# 2. 入れ子式の交差検証法を行う用意\n",
        "# 2.1 outer loopの設定\n",
        "outer_loop = KFold(n_splits=5, shuffle=True, random_state=0)\n",
        "\n",
        "# 2.2 inner loopの設定\n",
        "inner_loop = KFold(n_splits=4, shuffle=True, random_state=0)\n",
        "\n",
        "# 2.3 パイプライン生成\n",
        "pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                 ('logistic', LogisticRegression())])\n",
        "\n",
        "# 2.4 グリッドサーチの設定\n",
        "# 比較するハイパーパラメータ設定\n",
        "param_grid = {\n",
        "    'logistic__C': [1, 10, 100],\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(\n",
        "    estimator=pipe, param_grid=param_grid, scoring='accuracy', cv=inner_loop)\n",
        "\n",
        "# 3. 学習\n",
        "val_result = np.zeros((5, 3))  # outer_loop数×ハイパーパラメータの種類\n",
        "ol_index = 0  # outer_loopのindex\n",
        "\n",
        "# outer loop\n",
        "for train_val_index, test_index in outer_loop.split(X):\n",
        "    X_train_val, X_test = X[train_val_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_val_index], y[test_index]\n",
        "\n",
        "    # inner loop\n",
        "    gs.fit(X_train_val, y_train_val)  # trainで学習し、valで評価\n",
        "    val_result[ol_index] = gs.cv_results_[\"mean_test_score\"]\n",
        "\n",
        "    print(\" outer loopの結果その{}：{}\".format(ol_index+1,\n",
        "                                         val_result[ol_index]))\n",
        "    ol_index += 1\n",
        "\n",
        "# 4. 評価\n",
        "print(\"--\\n outer loopの平均結果 ：{}\\n--\".format(val_result.mean(axis=0)))\n",
        "# 出力すると3番目のハイパーパラメータ C=100が良いと分かる\n",
        "\n",
        "# 5. テストデータで性能確認\n",
        "clf_pipe = Pipeline([('scaler', StandardScaler()),\n",
        "                     ('logistic', LogisticRegression(C=100))])\n",
        "il_index = 0  # inner-loopのindex\n",
        "test_result = np.zeros(5*4)  # outer_loop数×inner_loop数\n",
        "\n",
        "# outer loop\n",
        "for train_val_index, test_index in outer_loop.split(X):\n",
        "    X_train_val, X_test = X[train_val_index], X[test_index]\n",
        "    y_train_val, y_test = y[train_val_index], y[test_index]\n",
        "\n",
        "    # inner loop\n",
        "    for train_index, val_index in inner_loop.split(X_train_val):\n",
        "        X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "        y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "        clf_pipe.fit(X_train, y_train)  # trainで学習し\n",
        "        test_result[il_index] = clf_pipe.score(X_test, y_test)  # testの正解率を求める\n",
        "\n",
        "        print(\" inner loopの結果その{}：{}\".format(il_index +\n",
        "                                             1, test_result[il_index]))\n",
        "        il_index += 1\n",
        "\n",
        "print(\"--\\n テストデータの平均正解率：{}\".format(test_result.mean()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}