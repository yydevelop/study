{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd0716fbbd92a13ad18c91e0530cf34e461b7b6b5d8d0684ef77aa6c15e96b2fbea",
   "display_name": "Python 3.8.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "カテゴリ一覧\n['alt.atheism',\n 'comp.graphics',\n 'comp.os.ms-windows.misc',\n 'comp.sys.ibm.pc.hardware',\n 'comp.sys.mac.hardware',\n 'comp.windows.x',\n 'misc.forsale',\n 'rec.autos',\n 'rec.motorcycles',\n 'rec.sport.baseball',\n 'rec.sport.hockey',\n 'sci.crypt',\n 'sci.electronics',\n 'sci.med',\n 'sci.space',\n 'soc.religion.christian',\n 'talk.politics.guns',\n 'talk.politics.mideast',\n 'talk.politics.misc',\n 'talk.religion.misc']\n\n\n記事その1\nNews Script:\nFrom: lerxst@wam.umd.edu (where's my thing)\nSubject: WHAT car is this!?\nNntp-Posting-Host: rac3.wam.umd.edu\nOrganization: University of Maryland, College Park\nLines: 15\n\n I was wondering if anyone out there could enlighten me on this car I saw\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\nthe front bumper was separate from the rest of the body. This is \nall I know. If anyone can tellme a model name, engine specs, years\nof production, where this car is made, history, or whatever info you\nhave on this funky looking car, please e-mail.\n\nThanks,\n- IL\n   ---- brought to you by your neighborhood Lerxst ----\n\n\n\n\n\n記事その1のカテゴリ\nText Category label: 7\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリのインポート\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from pprint import pprint\n",
    "\n",
    "# データセットの読み込み\n",
    "train_set = fetch_20newsgroups(subset='train', random_state=42)\n",
    "test_set = fetch_20newsgroups(subset='test', random_state=42)\n",
    "\n",
    "# 訓練データとテストデータの準備\n",
    "X_train = train_set.data\n",
    "y_train = train_set.target\n",
    "X_test = test_set.data\n",
    "y_test = test_set.target\n",
    "\n",
    "# 20種類のカテゴリ名・1番目の記事内容とカテゴリラベルの表示\n",
    "print('カテゴリ一覧')\n",
    "pprint(train_set.target_names)\n",
    "print('\\n')\n",
    "print('記事その1')\n",
    "print(f'News Script:\\n{X_train[0]}')\n",
    "print('記事その1のカテゴリ')\n",
    "print(f'Text Category label: {y_train[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(テキスト番号, 単語番号)  出現回数\n  (0, 4605)\t1\n  (0, 16574)\t1\n  (0, 18299)\t1\n  (0, 26070)\t1\n  (0, 34131)\t1\n  (0, 34943)\t1\n  (0, 35135)\t1\n  (0, 35560)\t1\n  (0, 37378)\t1\n  (0, 37722)\t5\n  (0, 40939)\t1\n  (0, 45232)\t1\n  (0, 48550)\t1\n  (0, 48552)\t1\n  (0, 50039)\t1\n  (0, 50455)\t2\n  (0, 51651)\t1\n  (0, 51714)\t1\n  (0, 57203)\t1\n  (0, 63238)\t1\n  (0, 63970)\t1\n  (0, 65968)\t1\n  (0, 67023)\t1\n  (0, 73061)\t1\n  (0, 74552)\t1\n  :\t:\n  (0, 79519)\t1\n  (0, 83103)\t1\n  (0, 86416)\t1\n  (0, 87451)\t1\n  (0, 90192)\t1\n  (0, 91885)\t1\n  (0, 94962)\t1\n  (0, 95944)\t1\n  (0, 98748)\t1\n  (0, 99619)\t1\n  (0, 101175)\t1\n  (0, 104609)\t1\n  (0, 105907)\t1\n  (0, 108033)\t1\n  (0, 109044)\t1\n  (0, 109354)\t1\n  (0, 111094)\t1\n  (0, 113755)\t1\n  (0, 114195)\t1\n  (0, 114439)\t1\n  (0, 118013)\t2\n  (0, 118714)\t1\n  (0, 122887)\t2\n  (0, 124627)\t1\n  (0, 127721)\t1\n\nBoW表現ベクトル\n[[0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリのインポート\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# BoW表現への変換（テキストをベクトル化）\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(X_train)\n",
    "X_train_bow = vectorizer.transform(X_train)\n",
    "X_test_bow = vectorizer.transform(X_test)\n",
    "\n",
    "# 1番目の文書のBoW表現のベクトルを表示\n",
    "print('(テキスト番号, 単語番号)  出現回数')\n",
    "print(X_train_bow[0])\n",
    "print('\\nBoW表現ベクトル')\n",
    "print(X_train_bow[0].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy: 0.951\nTest Accuracy: 0.811\n"
     ]
    }
   ],
   "source": [
    "# 必要なライブラリのインポート\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# MultinomialNBの適用(alpha=0.4)\n",
    "mnb = MultinomialNB(alpha=0.4)\n",
    "mnb.fit(X_train_bow, y_train)\n",
    "\n",
    "# Accuracyの表示\n",
    "print(f'Train Accuracy: {mnb.score(X_train_bow, y_train):.3f}')\n",
    "print(f'Test Accuracy: {mnb.score(X_test_bow, y_test):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train Accuracy(alpha=0.001): 0.988\n",
      "Test Accuracy(alpha=0.001): 0.799\n",
      "Train Accuracy(alpha=100): 0.747\n",
      "Test Accuracy(alpha=100): 0.632\n"
     ]
    }
   ],
   "source": [
    "mnb_small = MultinomialNB(alpha=0.001)\n",
    "mnb_small.fit(X_train_bow,y_train)\n",
    "\n",
    "mnb_large = MultinomialNB(alpha=100)\n",
    "mnb_large.fit(X_train_bow,y_train)\n",
    "\n",
    "# Accuracyの表示\n",
    "print(f'Train Accuracy(alpha=0.001): {mnb_small.score(X_train_bow, y_train):.3f}')\n",
    "print(f'Test Accuracy(alpha=0.001): {mnb_small.score(X_test_bow, y_test):.3f}')\n",
    "print(f'Train Accuracy(alpha=100): {mnb_large.score(X_train_bow, y_train):.3f}')\n",
    "print(f'Test Accuracy(alpha=100): {mnb_large.score(X_test_bow, y_test):.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}